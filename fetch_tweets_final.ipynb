{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43d6260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starte Tweet-Sammlung...\n",
      "Zwischenstand: 100 Tweets gesammelt...\n",
      "Zwischenstand: 200 Tweets gesammelt...\n",
      "Zwischenstand: 300 Tweets gesammelt...\n",
      "Zwischenstand: 399 Tweets gesammelt...\n",
      "Zwischenstand: 499 Tweets gesammelt...\n",
      "Zwischenstand: 599 Tweets gesammelt...\n",
      "Zwischenstand: 698 Tweets gesammelt...\n",
      "Zwischenstand: 798 Tweets gesammelt...\n",
      "Zwischenstand: 896 Tweets gesammelt...\n",
      "Zwischenstand: 996 Tweets gesammelt...\n",
      "Zwischenstand: 1096 Tweets gesammelt...\n",
      "Zwischenstand: 1196 Tweets gesammelt...\n",
      "Zwischenstand: 1296 Tweets gesammelt...\n",
      "Zwischenstand: 1396 Tweets gesammelt...\n",
      "Zwischenstand: 1496 Tweets gesammelt...\n",
      "Zwischenstand: 1596 Tweets gesammelt...\n",
      "Zwischenstand: 1696 Tweets gesammelt...\n",
      "Zwischenstand: 1795 Tweets gesammelt...\n",
      "Zwischenstand: 1895 Tweets gesammelt...\n",
      "Zwischenstand: 1995 Tweets gesammelt...\n",
      "Zwischenstand: 2095 Tweets gesammelt...\n",
      "Zwischenstand: 2194 Tweets gesammelt...\n",
      "Zwischenstand: 2294 Tweets gesammelt...\n",
      "Zwischenstand: 2394 Tweets gesammelt...\n",
      "Zwischenstand: 2494 Tweets gesammelt...\n",
      "Zwischenstand: 2594 Tweets gesammelt...\n",
      "Zwischenstand: 2694 Tweets gesammelt...\n",
      "Zwischenstand: 2793 Tweets gesammelt...\n",
      "Zwischenstand: 2893 Tweets gesammelt...\n",
      "Zwischenstand: 2993 Tweets gesammelt...\n",
      "Zwischenstand: 3093 Tweets gesammelt...\n",
      "Zwischenstand: 3193 Tweets gesammelt...\n",
      "Zwischenstand: 3292 Tweets gesammelt...\n",
      "Zwischenstand: 3392 Tweets gesammelt...\n",
      "Zwischenstand: 3492 Tweets gesammelt...\n",
      "Zwischenstand: 3591 Tweets gesammelt...\n",
      " Maximale Grenze von 3500 Tweets erreicht.\n",
      "\n",
      " 3591 Tweets erfolgreich gespeichert in 'fetched_tweets22.json'.\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# === API-Zugang ===\n",
    "api_token = \"<<BEARER TOKEN>>\"\n",
    "client = tweepy.Client(bearer_token=api_token, wait_on_rate_limit=True)\n",
    "\n",
    "# === Suchparameter ===\n",
    "search_term = \"munich -is:retweet lang:en\"\n",
    "max_results_per_call = 100\n",
    "output_file = \"fetched_tweets.json\"\n",
    "min_tweets = 3000\n",
    "max_tweets = 3500\n",
    "\n",
    "# === Ergebnis-Container ===\n",
    "collected_data = []\n",
    "all_raw_tweets = []\n",
    "\n",
    "# === Paginierung vorbereiten ===\n",
    "paginator = tweepy.Paginator(\n",
    "    client.search_recent_tweets,\n",
    "    query=search_term,\n",
    "    tweet_fields=[\"entities\", \"context_annotations\"],\n",
    "    user_fields=[\"id\", \"username\", \"name\"],\n",
    "    expansions=[\"author_id\"],\n",
    "    max_results=max_results_per_call\n",
    ")\n",
    "\n",
    "print(\"Starte Tweet-Sammlung...\")\n",
    "\n",
    "# === Tweets sammeln ===\n",
    "for page in paginator:\n",
    "    user_lookup = {}\n",
    "\n",
    "    # Benutzer-Infos auflösen\n",
    "    if page.includes and \"users\" in page.includes:\n",
    "        user_lookup = {user.id: user.username for user in page.includes[\"users\"]}\n",
    "\n",
    "    # Tweets verarbeiten\n",
    "    if page.data is None:\n",
    "        print(\" Keine weiteren Tweets gefunden.\")\n",
    "        break\n",
    "\n",
    "    for tweet in page.data:\n",
    "        all_raw_tweets.append(tweet)\n",
    "\n",
    "        user = user_lookup.get(tweet.author_id, \"unknown\")\n",
    "\n",
    "        collected_data.append({\n",
    "            \"id\": tweet.id,\n",
    "            \"username\": user,\n",
    "            \"author_id\": tweet.author_id,\n",
    "            \"text\": tweet.text,\n",
    "            \"entities\": tweet.entities,\n",
    "            \"context_annotations\": tweet.context_annotations,\n",
    "            \"created_at\": tweet.created_at.isoformat() if tweet.created_at else None\n",
    "        })\n",
    "\n",
    "    print(f\"Zwischenstand: {len(collected_data)} Tweets gesammelt...\")\n",
    "\n",
    "    # Abbruchbedingung bei Erreichen von max_tweets\n",
    "    if len(collected_data) >= max_tweets:\n",
    "        print(f\" Maximale Grenze von {max_tweets} Tweets erreicht.\")\n",
    "        break\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "# === Überprüfen ob Mindestgrenze erreicht wurde ===\n",
    "if len(collected_data) < min_tweets:\n",
    "    print(f\" Nur {len(collected_data)} Tweets gefunden (weniger als {min_tweets}).\")\n",
    "else:\n",
    "    # Als JSON speichern\n",
    "    df = pd.DataFrame(collected_data)\n",
    "    df.to_json(output_file, orient=\"records\", indent=2, force_ascii=False)\n",
    "    print(f\"\\n {len(df)} Tweets erfolgreich gespeichert in '{output_file}'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
